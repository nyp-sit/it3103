{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/it3103/blob/main/week3/multi_class_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RZIgnFFEv5t"
   },
   "source": [
    "# Lab Exercise: Multi-class Image Classification\n",
    "\n",
    "Now that you have learnt how to train a model to do binary image classification of cats and dogs using Convolutional Neural Network. \n",
    "\n",
    "Modify the code to train a model to recognise whether a hand gesture is one of the gesture in the rock, paper and scissor game. \n",
    "\n",
    "The dataset of rock paper scissor can be downloaded from https://nypai.s3-ap-southeast-1.amazonaws.com/datasets/rps2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22qK2vQiEqgB"
   },
   "source": [
    "### Step 1: Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0Widz3qoiVr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKGTrOeiEzmP"
   },
   "source": [
    "### Step 2: Download Datasets\n",
    "\n",
    "Download the dataset and unzip the file to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YH_eNtAbn78U"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcaiLftXEONn"
   },
   "source": [
    "### Step 3: Set up your train and validation directory. \n",
    "\n",
    "Examine your dataset folder and set your train_dir and validation_dir to point to the correct directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9N0WuIbxwJGb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk2edwW2FJ1d"
   },
   "source": [
    "### Step 4: Set up the  tf.keras.preprocessing.image_dataset_from_directory()\n",
    "\n",
    "Set up the  tf.keras.preprocessing.image_dataset_from_directory() for both train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5-bXiSWoFtW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpaO7BJVxkAO"
   },
   "source": [
    "You can see the labels is **NOT** one-hot-encoded.  Try changing the class_mode to 'categorical' and observe that the label will be one-hot-encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrSOVvwfFpcz"
   },
   "source": [
    "Print out the class indices so that you know what label is assigned to which class.  Hint: use ``class_indices`` of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPs--CSYvpmT"
   },
   "outputs": [],
   "source": [
    "## print out the class indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4kbK7XpGLYc"
   },
   "source": [
    "### Step 5: Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZCiZLK9vupW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2It5kjbGZA0"
   },
   "source": [
    "### Step 6: Compile and Train the Model\n",
    "\n",
    "Make sure you choose the correct loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTPLmxO5IvaD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wkt7heeK2aj"
   },
   "source": [
    "Visualize your training using Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOXpmCBGI8Ql"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i3Z8WIQJLi1"
   },
   "source": [
    "### Step 7: Save your Model\n",
    "\n",
    "Save your model for use in inference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PprYt9Sz0oUM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkWGYOK4HGBE"
   },
   "source": [
    "### Test your model\n",
    "\n",
    "The following code cells shows you how to set up Google Colab to take a picture using your webcam. Take a picture of your hand gesture (rock, paper or scissors) and infer using your saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWkCXDE70WiA"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qp5MYbtv0WiD"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGPl4D2XLDb3"
   },
   "source": [
    "Write code to read the image and reshape the tensor (to include batch axis) and use your model to predict the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jm3XARik0eT_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "multi-class-image-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
