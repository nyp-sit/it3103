{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/it3103/blob/main/week3/multi_class_image_classification_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RZIgnFFEv5t"
      },
      "source": [
        "# Lab Exercise: Multi-class Image Classification\n",
        "\n",
        "Now that you have learnt how to train a model to do binary image classification of cats and dogs using Convolutional Neural Network. \n",
        "\n",
        "Modify the code to train a model to recognise whether a hand gesture is one of the gesture in the rock, paper and scissor game. \n",
        "\n",
        "The dataset of rock paper scissor can be downloaded from https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/datasets/rps2.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22qK2vQiEqgB"
      },
      "source": [
        "### Step 1: Import the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0Widz3qoiVr"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGTrOeiEzmP"
      },
      "source": [
        "### Step 2: Download Datasets\n",
        "\n",
        "Download the dataset and unzip the file to a folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH_eNtAbn78U"
      },
      "outputs": [],
      "source": [
        "dataset_URL = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/datasets/rps2.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('rps2.zip', origin=dataset_URL, extract=True, cache_dir='.')\n",
        "print(path_to_zip)\n",
        "dataset_dir = os.path.join(os.path.dirname(path_to_zip), 'rps2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcFrAdJN5cE8"
      },
      "outputs": [],
      "source": [
        "print(dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcaiLftXEONn"
      },
      "source": [
        "### Step 3: Set up your directory. \n",
        "\n",
        "Examine your dataset folder and set your dataset directory to point to the correct directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N0WuIbxwJGb"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(dataset_dir, \"train\")\n",
        "validation_dir = os.path.join(dataset_dir, \"validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk2edwW2FJ1d"
      },
      "source": [
        "### Step 4: Set up the  tf.keras.preprocessing.image_dataset_from_directory()\n",
        "\n",
        "Set up the  tf.keras.preprocessing.image_dataset_from_directory() for both train and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5-bXiSWoFtW"
      },
      "outputs": [],
      "source": [
        "img_height, img_width = 128, 128\n",
        "batch_size = 32\n",
        "\n",
        "# resize all the images to the same size as expected by VGG model we downloaded above\n",
        "image_size = (img_height, img_width)\n",
        "\n",
        "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='int'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr2vIveD57Qr"
      },
      "outputs": [],
      "source": [
        "for images, labels in train_ds.take(1):\n",
        "    print('images shape:', images.shape)\n",
        "    print('labels shape:', labels.shape)\n",
        "    print(tf.squeeze(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpaO7BJVxkAO"
      },
      "source": [
        "You can see the labels is **NOT** one-hot-encoded.  Try changing the class_mode to 'categorical' and observe that the label will be one-hot-encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrSOVvwfFpcz"
      },
      "source": [
        "Print out the class indices so that you know what label is assigned to which class.  Hint: use ``class_names`` of the generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPs--CSYvpmT"
      },
      "outputs": [],
      "source": [
        "## print out the class indices\n",
        "print(train_ds.class_names)\n",
        "print(val_ds.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4kbK7XpGLYc"
      },
      "source": [
        "### Step 5: Create your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZCiZLK9vupW"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(128, 128, 3)))\n",
        "    model.add(keras.layers.Rescaling(scale=1./255))\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\n",
        "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = make_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2It5kjbGZA0"
      },
      "source": [
        "### Step 6: Compile and Train the Model\n",
        "\n",
        "Make sure you choose the correct loss function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTPLmxO5IvaD"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wkt7heeK2aj"
      },
      "source": [
        "Visualize your training using Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOXpmCBGI8Ql"
      },
      "outputs": [],
      "source": [
        "def create_tb_callback(): \n",
        "\n",
        "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
        "\n",
        "    def get_run_logdir():    # use a new directory for each run\n",
        "\t    import time\n",
        "\t    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "\t    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "    run_logdir = get_run_logdir()\n",
        "\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "    return tb_callback\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"bestcheckpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[create_tb_callback(), model_checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i3Z8WIQJLi1"
      },
      "source": [
        "### Step 7: Save your Model\n",
        "\n",
        "Save your model for use in inference later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PprYt9Sz0oUM"
      },
      "outputs": [],
      "source": [
        "keras.models.save_model(model, filepath=\"rps_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWGYOK4HGBE"
      },
      "source": [
        "### Test your model\n",
        "\n",
        "The following code cells shows you how to set up Google Colab to take a picture using your webcam. Take a picture of your hand gesture (rock, paper or scissors) and infer using your saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWkCXDE70WiA"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp5MYbtv0WiD"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGPl4D2XLDb3"
      },
      "source": [
        "Write code to read the image and reshape the tensor (to include batch axis) and use your model to predict the label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm3XARik0eT_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    filename, target_size=(128, 128)\n",
        ")\n",
        "\n",
        "# we convert the image to numpy array\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# Although we only have single image, however our model expected data in batches\n",
        "# so we will need to add in the batch axis too\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "# we load the model saved earlier and do the inference \n",
        "model = tf.keras.models.load_model('rps_model')\n",
        "predicted_label = model.predict(img_array)\n",
        "# or predicted_label = model(img_array)\n",
        "\n",
        "print(np.argmax(predicted_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxJ6xc05_U-3"
      },
      "outputs": [],
      "source": [
        "val_ds.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej1QyxAQ_f5r"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multi-class-image-classification.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}